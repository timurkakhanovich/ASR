{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98dde57d-1450-486e-900a-3aa180760304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    Speech2TextProcessor, \n",
    "    Speech2TextTokenizer, \n",
    "    Speech2TextForConditionalGeneration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c78a66-27b8-40f2-95f6-1b65b522440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "tokenizer = Speech2TextTokenizer.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-medium-mustc-multilingual-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c144e07-cddd-4275-bacb-b56a7de10219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sample: Tuple[torch.Tensor, int, str, int, int, int]) -> Dict[str, torch.Tensor]:\n",
    "    batch = dict()\n",
    "    batch[\"input_values\"] = processor(\n",
    "        sample[0][0], sampling_rate=16_000, return_tensors=\"pt\"\n",
    "    ).input_features[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(sample[2], return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10048a2d-28de-4d2f-886a-8f4227fa8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchaudio.datasets.LIBRISPEECH(root=\"\", url='dev-clean')\n",
    "dataset = dataset.map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f026bec4-36cb-4239-aadb-05d8bb315287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[-1.7439, -1.5824, -1.3852,  ..., -1.4764, -1.3188, -1.5373],\n",
       "         [-1.7372, -1.5597, -1.5623,  ..., -1.3479, -1.4273, -1.6317],\n",
       "         [-1.4334, -1.3532, -1.2806,  ..., -1.5108, -1.3358, -1.4236],\n",
       "         ...,\n",
       "         [-1.6064, -1.5294, -1.5514,  ..., -1.0002, -1.0575, -1.0322],\n",
       "         [-1.7444, -1.6128, -1.4223,  ..., -1.0696, -0.9122, -1.0744],\n",
       "         [-1.3830, -1.3087, -1.3786,  ..., -1.0823, -1.0664, -1.1232]]),\n",
       " 'labels': tensor([[ 129, 8053,   66,   30,    4, 5878,    8,    4, 1080, 3353,    5,    6,\n",
       "            52,   60,  534,    9, 1524,   20, 5517,    2]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e11a306f-b524-4fcd-b758-23797c66fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollator(object):\n",
    "    def __init__(self, processor: Speech2TextProcessor, padding=True, \n",
    "                 max_length=None, max_length_labels=None, \n",
    "                 pad_to_multiple_of=None, pad_to_multiple_of_labels=None):\n",
    "        self.processor = processor\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "        self.max_length_labels = max_length_labels\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "        self.pad_to_multiple_of_labels = pad_to_multiple_of_labels\n",
    "    \n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        \n",
    "        batch = self.processor.pad(\n",
    "            input_features, \n",
    "            padding=self.padding, \n",
    "            max_length=self.max_length, \n",
    "            pad_to_multiple_of=self.pad_to_multiple_of, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features, \n",
    "                padding=self.padding, \n",
    "                max_length=self.max_length, \n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "        \n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        \n",
    "        batch[\"labels\"] = labels\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80b2926e-9243-4eb7-aa5d-723380a54062",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a56d49fb-b54f-4321-a052-3ee89c485885",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [dataset[0], dataset[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fee06ecd-f9a3-4fdc-aab1-010f8418c515",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Speech2TextProcessor' object has no attribute 'pad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mDataCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     13\u001b[0m input_features \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m     14\u001b[0m label_features \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m---> 16\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m(\n\u001b[1;32m     17\u001b[0m     input_features, \n\u001b[1;32m     18\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \n\u001b[1;32m     19\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length, \n\u001b[1;32m     20\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_to_multiple_of, \n\u001b[1;32m     21\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mas_target_processor():\n\u001b[1;32m     25\u001b[0m     labels_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     26\u001b[0m         label_features, \n\u001b[1;32m     27\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Speech2TextProcessor' object has no attribute 'pad'"
     ]
    }
   ],
   "source": [
    "data_collator(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01e645-3df8-4465-ad52-467d6eafaaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
