{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e59b7b-da04-4c7f-9f99-32f3a76cf572",
   "metadata": {},
   "source": [
    "# QuartzNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f501668-618a-4b81-b1ca-798c65984054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "from typing import Dict, Union\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0df75f-8d69-45fe-a854-8f6dc83e46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ccbc4-b9b8-4bd4-a46b-3d05b5f884c3",
   "metadata": {},
   "source": [
    "## Data preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b4d93d2-559c-4e49-b38b-23bf3acbb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASRProcessor(object):\n",
    "    def __init__(self, sampling_rate, n_fft=1024, hop_length=512, n_mels=128):\n",
    "        self.audio_preprocessor = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sampling_rate, \n",
    "            n_fft=n_fft, \n",
    "            hop_length=hop_length, \n",
    "            n_mels=n_mels\n",
    "        )\n",
    "        \n",
    "        self.let2idx = [s for s in string.ascii_lowercase]\n",
    "        self.let2idx.extend([\" \", \"'\", \"<EOS>\", \"<PAD>\"])\n",
    "        self.vocab = {w: idx for idx, w in enumerate(self.let2idx)}\n",
    "\n",
    "    def text_preprocessor(self, text):\n",
    "        sym_tokenize = [s for s in text]\n",
    "        \n",
    "        return torch.LongTensor([self.vocab[symbol] for symbol in sym_tokenize])\n",
    "    \n",
    "    def __call__(self, input_values: torch.tensor, labels: str) -> Dict[str, Union[torch.tensor, torch.LongTensor]]:\n",
    "        return {\n",
    "            'input_features': self.audio_preprocessor(input_values), \n",
    "            'labels': self.text_preprocessor(labels)\n",
    "        }\n",
    "    \n",
    "    def labels_decode(self, labels):\n",
    "        return ''.join([self.let2idx[l] for l in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c4c3e-3638-4407-ae17-5a73c513391c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b379dd-8d43-4d5a-a2c1-81668acd9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, root='', split='val', max_length=150):\n",
    "        assert split in ['dev-clean', 'dev-other', 'test-clean', 'test-other', 'train-clean-100'], \\\n",
    "                'Split error!'\n",
    "        \n",
    "        self.data_iterator = torchaudio.datasets.LIBRISPEECH(root=root, url=split)\n",
    "        \n",
    "        self.processor = ASRProcessor(sampling_rate=16000)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_iterator[idx]\n",
    "        sample = self.processor(sample[0][0], sample[2].lower())\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_iterator)\n",
    "    \n",
    "    @staticmethod\n",
    "    def batch_collate(batch):\n",
    "        # Collate audio samples.  \n",
    "        batch_tokens_lengths = torch.tensor([x['input_features'].size(1) for x in batch])\n",
    "        max_len_per_batch = torch.max(batch_tokens_lengths)\n",
    "        \n",
    "        # Extend to even max_len.  \n",
    "        max_len_per_batch += (max_len_per_batch % 2)\n",
    "        lengths_to_pad = max_len_per_batch - batch_tokens_lengths - 1\n",
    "        \n",
    "        input_features = torch.stack([\n",
    "            F.pad(x['input_features'], pad=(0, val_to_pad)) \n",
    "            for x, val_to_pad in zip(batch, lengths_to_pad)\n",
    "        ])\n",
    "        \n",
    "        # Collate label samples.  \n",
    "        batch_tokens_lengths = torch.tensor([len(x['labels']) for x in batch])\n",
    "        max_len_per_batch = torch.max(batch_tokens_lengths)\n",
    "        \n",
    "        # Extend to even max_len.  \n",
    "        max_len_per_batch += (max_len_per_batch % 2)\n",
    "        lengths_to_pad = max_len_per_batch - batch_tokens_lengths - 1\n",
    "\n",
    "        labels = torch.vstack([\n",
    "            F.pad(x['labels'], pad=(0, val_to_pad), value=29) \n",
    "            for x, val_to_pad in zip(batch, lengths_to_pad)\n",
    "        ]).type(torch.int64)\n",
    "\n",
    "        return {\n",
    "            'input_features': input_features, \n",
    "            'labels': labels\n",
    "        }\n",
    "    \n",
    "    def labels_decode(self, labels):\n",
    "        return self.processor.labels_decode(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5651554b-e5aa-485b-8508-1008f92de7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': LibriDataset(split='train-clean-100'), \n",
    "    'val': LibriDataset(split='dev-clean')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d273c1-5731-4377-a376-b2b3477deb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    k: DataLoader(dataset[k], batch_size=BATCH_SIZE, shuffle=True, \n",
    "                    collate_fn=LibriDataset.batch_collate, num_workers=1)\n",
    "    for k in dataset.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b890add-9628-428c-a401-a0fac9e8e2f7",
   "metadata": {},
   "source": [
    "## Model (QuartzNet 5x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2e5e8ae-7a85-41da-aeff-a6eeb1cc5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleBBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, activation=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.depthwise = nn.Conv1d(\n",
    "            in_channels, in_channels, kernel_size, \n",
    "            padding=padding, groups=in_channels\n",
    "        )\n",
    "        self.pointwise = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        TCS_out = self.pointwise(self.depthwise(x))\n",
    "        \n",
    "        bn_out = self.batch_norm(TCS_out)\n",
    "        \n",
    "        return F.relu(bn_out) if self.activation else bn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "542c83a9-0a60-420d-b973-8aab23e4f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatedBBlocks(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, R):\n",
    "        super().__init__()\n",
    "        # The first block to match in_channels and out_channels\n",
    "        self.B = [SingleBBlock(in_channels, out_channels, kernel_size, activation=True)]\n",
    "        \n",
    "        # BBlocks between the first and the last blocks.  \n",
    "        self.B.extend([\n",
    "            SingleBBlock(out_channels, out_channels, kernel_size, activation=True)\n",
    "            for _ in range(R - 2)\n",
    "        ])\n",
    "        \n",
    "        # The last block to prevent nonlinearity.  \n",
    "        self.B.append(SingleBBlock(out_channels, out_channels, kernel_size, activation=False))\n",
    "        self.B = nn.Sequential(*self.B)\n",
    "        \n",
    "        # Skip connection.  \n",
    "        self.skip_connection = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1), \n",
    "            nn.BatchNorm1d(num_features=out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        RBlocks_out = self.B(x)\n",
    "        skip_out = self.skip_connection(x)\n",
    "        \n",
    "        return F.relu(RBlocks_out + skip_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d816a157-69e4-4723-bb54-ddb0d7f3e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuartzNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.C1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=33, stride=2), \n",
    "            nn.BatchNorm1d(num_features=256), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.B = nn.Sequential(\n",
    "            OrderedDict([\n",
    "                ('B1', RepeatedBBlocks(in_channels=256, out_channels=256, kernel_size=33, R=5)), \n",
    "                ('B2', RepeatedBBlocks(in_channels=256, out_channels=256, kernel_size=39, R=5)), \n",
    "                ('B3', RepeatedBBlocks(in_channels=256, out_channels=512, kernel_size=51, R=5)), \n",
    "                ('B4', RepeatedBBlocks(in_channels=512, out_channels=512, kernel_size=63, R=5)), \n",
    "                ('B5', RepeatedBBlocks(in_channels=512, out_channels=512, kernel_size=75, R=5))\n",
    "            ])\n",
    "        )\n",
    "        self.C2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=87, padding=43), \n",
    "            nn.BatchNorm1d(num_features=512), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.C3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=512, out_channels=1024, kernel_size=1), \n",
    "            nn.BatchNorm1d(num_features=1024), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.C4 = nn.Conv1d(in_channels=1024, out_channels=29, kernel_size=1, dilation=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        first_conv_out = self.C1(x)\n",
    "        b_out = self.B(first_conv_out)\n",
    "        c2_out = self.C2(b_out)\n",
    "        c3_out = self.C3(c2_out)\n",
    "        c4_out = self.C4(c3_out)\n",
    "        \n",
    "        return c4_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa4bec29-1f3c-42de-817f-03f295072510",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_it = iter(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c05e2165-6ec5-41b4-9f48-ce3c3cbb31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(data_it)['input_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "33aa0de4-1cfe-4312-bf14-2a1aebf3fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuartzNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5cac12e7-d97d-412c-a770-4acb65e02876",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8d87efde-c891-4a00-b2f8-36db111bbe43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 29, 241])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6522042-6502-4f2c-9a15-5e6076ca329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
